{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-do\n",
    "- [ ] verify black scholes for puts\n",
    "- [ ] make protects\n",
    "- [ ] make orders for oprhans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS CELL SHOULD BE IN ALL VSCODE NOTEBOOKS ##\n",
    "\n",
    "# Set the root\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from sysconfig import get_path\n",
    "\n",
    "import pandas as pd\n",
    "from from_root import from_root\n",
    "from ib_async import util\n",
    "\n",
    "MARKET = \"SNP\"\n",
    "\n",
    "ROOT = from_root()\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "\n",
    "\n",
    "# Add `src` and ROOT to _src.pth in .venv to allow imports in VS Code\n",
    "if \"src\" not in Path.cwd().parts:\n",
    "    src_path = str(Path(get_path(\"purelib\")) / \"_src.pth\")\n",
    "    with open(src_path, \"w\") as f:\n",
    "        f.write(str(ROOT / \"src\\n\"))\n",
    "        f.write(str(ROOT))\n",
    "        if str(ROOT) not in sys.path:\n",
    "            sys.path.insert(1, str(ROOT))\n",
    "\n",
    "# Start the Jupyter loop\n",
    "util.startLoop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "first und ivs: 100%|██████████| 233/233 [00:24<00:00,  9.58chunk/s]\n",
      "second und ivs: 100%|██████████| 14/14 [00:12<00:00,  1.16chunk/s]\n",
      "raw chains: 100%|██████████| 233/233 [00:49<00:00,  4.70chunk/s]\n",
      "missing chains: 100%|██████████| 226/226 [00:48<00:00,  4.64chunk/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'expiry'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31660\\3729436271.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mchains\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_chains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raw chains'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0munds1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_ib_util_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mmissing_unds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munds1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0munds1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'symbol'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'symbol'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmissing_unds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0madditional_chains\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_chains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_unds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'missing chains'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mchains\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madditional_chains\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mchains\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchains_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kashi\\python\\snp\\.venv\\Lib\\site-packages\\nest_asyncio.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mtask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m                 \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCancelledError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                     \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kashi\\python\\snp\\.venv\\Lib\\site-packages\\nest_asyncio.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     94\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[0;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\futures.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0m_FINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidStateError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Result is not ready.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    331\u001b[0m                 self._loop.call_soon(\n\u001b[0;32m    332\u001b[0m                     self.__step, new_exc, context=self._context)\n\u001b[0;32m    333\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[0m_leave_task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# Needed to break cycles when an exception occurs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\python\\snp\\src\\ibfuncs.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(ib, stocks, sleep_time, msg)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0mdf_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_rows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# set expiry time to EST 4:00 PM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;31m# exp_time = pd.to_datetime(df_out.expiry).dt.tz_localize('US/Eastern').apply(lambda x: x.replace(hour=16, minute=0, second=0))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     \u001b[0mdf_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dte'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dte\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpiry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kashi\\python\\snp\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'expiry'"
     ]
    }
   ],
   "source": [
    "# get portfolio, undsymbols and openorders\n",
    "\n",
    "import asyncio\n",
    "import numpy as np\n",
    "\n",
    "from ibfuncs import df_chains, df_iv, get_ib, get_open_orders, quick_pf\n",
    "from snp import get_snp_unds\n",
    "from utils import clean_ib_util_df, how_many_days_old, load_config, pickle_me\n",
    "\n",
    "config = load_config('SNP')\n",
    "\n",
    "unds_path = ROOT/'data'/'snp_unds.pkl'\n",
    "chains_path = ROOT /'data'/'chains.pkl'\n",
    "\n",
    "# age check\n",
    "MAX_FILE_AGE = config.get('MAX_FILE_AGE')\n",
    "age_should_be_less_than = MAX_FILE_AGE # Note: unds_path is used to check the age for all files\n",
    "recreate = chain_recreate = False\n",
    "\n",
    "if how_many_days_old(unds_path) is None or (how_many_days_old(unds_path) > age_should_be_less_than):\n",
    "    recreate = True\n",
    "\n",
    "if how_many_days_old(chains_path) is None or (how_many_days_old(chains_path) > age_should_be_less_than):\n",
    "    chain_recreate = True\n",
    "\n",
    "if recreate:\n",
    "    unds = get_snp_unds()\n",
    "    pickle_me(unds, unds_path)\n",
    "\n",
    "else:\n",
    "    unds = pd.read_pickle(unds_path)\n",
    "\n",
    "with get_ib('SNP') as ib:\n",
    "\n",
    "    unds_iv=ib.run(df_iv(ib=ib, stocks=unds, msg='first und ivs'))\n",
    "\n",
    "    no_price=unds_iv[unds_iv[['price', 'hv', 'iv']].isnull().any(axis=1)].symbol.to_list()\n",
    "    second_unds_iv = ib.run(df_iv(ib=ib, stocks=no_price, sleep_time=10, msg='second und ivs'))\n",
    "\n",
    "    pf_raw = quick_pf(ib)\n",
    "    oo = get_open_orders(ib)\n",
    "\n",
    "    # Set symbol as index for both dataframes\n",
    "    cols = ['symbol', 'price', 'iv', 'hv']\n",
    "\n",
    "    unds_iv = unds_iv[cols].set_index('symbol')\n",
    "    second_unds_iv = second_unds_iv[cols].set_index('symbol')\n",
    "\n",
    "    # Update unds_iv with non-null values from second_unds_iv \n",
    "    unds_iv.update(second_unds_iv)\n",
    "\n",
    "    # unds_iv = unds_iv.set_index('symbol')[['hv', 'iv', 'price']]\n",
    "    unds_iv.columns = ['und_' + col for col in unds_iv.columns]\n",
    "    unds_iv = unds_iv.reset_index()\n",
    "\n",
    "    # ... add und_price\n",
    "    pf = pf_raw.merge(unds_iv, on='symbol', how='left')\n",
    "\n",
    "    # Update und_price with mktPrice where und_price is NaN and mktPrice has a value\n",
    "    pf.loc[pd.isna(pf['und_price']) & pd.notna(pf['mktPrice']), 'und_price'] = pf['mktPrice']\n",
    "\n",
    "    # Merge the DataFrames on 'symbol'\n",
    "    unds_iv = unds_iv.merge(pf[['symbol', 'und_price']], on='symbol', how='left')\n",
    "\n",
    "    # Fill NaN values in 'und_price_x' with values from 'und_price_y'\n",
    "    unds_iv['und_price'] = unds_iv['und_price_x'].fillna(unds_iv['und_price_y'])\n",
    "\n",
    "    # Drop the unnecessary 'und_price_x' and 'und_price_y' columns\n",
    "    unds_iv = unds_iv.drop(columns=['und_price_x', 'und_price_y'])\n",
    "\n",
    "    # ...temp store the pf, oo\n",
    "    pf_path = ROOT / 'data' / 'pf.pkl'\n",
    "    oo_path = ROOT / 'data' / 'oo.pkl'\n",
    "\n",
    "    if chain_recreate:\n",
    "        chains = asyncio.run(df_chains(ib, unds, msg='raw chains'))\n",
    "        unds1 = clean_ib_util_df(unds)\n",
    "        missing_unds = unds1[~unds1['symbol'].isin(chains['symbol'])]\n",
    "        if not missing_unds.empty:\n",
    "            additional_chains = asyncio.run(df_chains(ib, missing_unds.contract.to_list(), msg='missing chains'))\n",
    "            chains = pd.concat([chains, additional_chains], ignore_index=True)\n",
    "    else:\n",
    "        chains = pd.read_pickle(chains_path)\n",
    "\n",
    "pickle_me(pf, pf_path)\n",
    "pickle_me(oo, oo_path)\n",
    "pickle_me(chains, chains_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique symbols in each DataFrame\n",
    "unds_df = clean_ib_util_df(unds)\n",
    "unique_unds_symbols = len([u.symbol for u in unds])\n",
    "unique_chains_symbols = chains['symbol'].nunique()\n",
    "unique_oo_symbols = oo['symbol'].nunique() if 'symbol' in oo.columns else None\n",
    "unique_pf_symbols = pf['symbol'].nunique() if 'symbol' in pf.columns else None\n",
    "\n",
    "# Display the counts\n",
    "unique_symbols_count = {\n",
    "    'und symbols': (unique_unds_symbols, f\"{how_many_days_old(unds_path):.2f} days old.\"),\n",
    "    'chain symbols': (unique_chains_symbols, f\"{how_many_days_old(chains_path):.2f} days old.\"),\n",
    "    'portfolio symbols': (unique_pf_symbols, \"0.00 days old.\"),\n",
    "    'open order symbols': (unique_oo_symbols, f\"{how_many_days_old(oo_path):.2f} days old.\"),\n",
    "}\n",
    "display(unique_symbols_count)\n",
    "\n",
    "# Find symbols missing in unds, chains, and pf\n",
    "missing_in_unds = chains[~chains['symbol'].isin(unds_df['symbol'])]\n",
    "missing_in_chains = unds_df[~unds_df['symbol'].isin(chains['symbol'])]\n",
    "missing_in_chains_from_pf = pf[~pf['symbol'].isin(chains['symbol'])]\n",
    "\n",
    "# Display missing symbols as lists\n",
    "print(\"Symbols missing in unds from chains:\", missing_in_unds['symbol'].unique().tolist())\n",
    "print(\"Symbols missing in chains from unds:\", missing_in_chains['symbol'].unique().tolist())\n",
    "print(\"Symbols missing in chains from pf:\", missing_in_chains_from_pf['symbol'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify positions\n",
    "Positions are classified as follows:\n",
    "- `cwp`: the perfect position that is protected and has a cover.\n",
    "- `exposed`: stocks that need to be covered and protected.\n",
    "- `uncovered`: stocks that need to be only covered by options.\n",
    "- `unprotected`: stocks that need to be only protected by options.\n",
    "- `orphaned`: options that have no underlying stocks positions.\n",
    "- `covering`: options that are covering positions.\n",
    "- `protecting`: options that are portecting positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def make_strategy(pf):\n",
    "    \"\"\"\n",
    "    Classifies trading strategies in a portfolio based on option and stock positions.\n",
    "    \n",
    "    Parameters:\n",
    "    pf (pd.DataFrame): Portfolio DataFrame containing columns:\n",
    "        - symbol: Ticker symbol\n",
    "        - secType: Security type ('STK' or 'OPT')\n",
    "        - right: Option right ('C', 'P', or '0' for stocks)\n",
    "        - expiry: Option expiration date\n",
    "        - strike: Option strike price\n",
    "        - position: Position size (positive or negative)\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Original DataFrame with added 'strategy' column containing classifications:\n",
    "        - straddled: Matching call and put options\n",
    "        - covering: Short calls or puts with underlying stock\n",
    "        - protecting: Long calls or puts with underlying stock\n",
    "        - cwp: Perfect. Stock with both covering and protecting options\n",
    "        - unprotected: Stock with only covering options\n",
    "        - uncovered: Stock with only protecting options\n",
    "        - orphaned: Options without matching stock position\n",
    "        - exposed: Stock positions without options\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    pf = pf.copy()\n",
    "    \n",
    "    # Sort by covered with protection pairs\n",
    "    right_order = {'C': 0, '0': 1, 'P': 2}\n",
    "    \n",
    "    pf = pf.sort_values(\n",
    "        by=['symbol', 'right'],\n",
    "        key=lambda x: x.map(right_order) if x.name == 'right' else x\n",
    "    )\n",
    "    \n",
    "    # Initialize strategy field with blank underscore\n",
    "    pf['strategy'] = 'tbd'\n",
    "    \n",
    "    # Filter for options only\n",
    "    opt_pf = pf[pf.secType == 'OPT']\n",
    "    \n",
    "    # Group by symbol and expiry to find matching calls and puts\n",
    "    straddled = (opt_pf.groupby(['symbol', 'expiry', 'strike'])\n",
    "                       .filter(lambda x: (\n",
    "                           # Must have exactly 2 rows (call and put)\n",
    "                           len(x) == 2 and\n",
    "                           # Must have both C and P\n",
    "                           set(x['right']) == {'C', 'P'} and\n",
    "                           # Position signs must match\n",
    "                           np.sign(x['position'].iloc[0]) == np.sign(x['position'].iloc[1])\n",
    "                       )))\n",
    "    \n",
    "    # Update strategy field for straddles\n",
    "    pf.loc[pf.index.isin(straddled.index), 'strategy'] = 'straddled'\n",
    "    \n",
    "    # Filter for stocks and their associated options\n",
    "    cwp = (pf.groupby('symbol')\n",
    "             .filter(lambda x: (\n",
    "                 # Must have exactly one STK row\n",
    "                 (x.secType == 'STK').sum() == 1 and\n",
    "                 # Must have 1 or 2 OPT rows\n",
    "                 (x.secType == 'OPT').sum() in [1, 2]\n",
    "             )))\n",
    "    \n",
    "    # Update strategy field for covered calls/puts\n",
    "    pf.loc[cwp.index, 'strategy'] = cwp.apply(\n",
    "        lambda x: 'covering' if (x['right'] == 'C' and x['position'] < 0) or \n",
    "                               (x['right'] == 'P' and x['position'] < 0) \n",
    "                 else 'protecting', \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Update strategy field for stocks with both covering and protecting\n",
    "    stocks_with_both = pf[(pf.secType == 'STK') &\n",
    "                         pf.symbol.isin(pf[(pf.strategy == 'covering')].symbol) &\n",
    "                         pf.symbol.isin(pf[(pf.strategy == 'protecting')].symbol)]\n",
    "    pf.loc[stocks_with_both.index, 'strategy'] = 'cwp'\n",
    "    \n",
    "    # Update strategy field for stocks with covering but no protecting\n",
    "    stocks_covered_only = pf[(pf.secType == 'STK') &\n",
    "                            pf.symbol.isin(pf[(pf.strategy == 'covering')].symbol) &\n",
    "                            ~pf.symbol.isin(pf[(pf.strategy == 'protecting')].symbol)]\n",
    "    pf.loc[stocks_covered_only.index, 'strategy'] = 'unprotected'\n",
    "    \n",
    "    # Update strategy field for stocks with protecting but no covering  \n",
    "    stocks_protected_only = pf[(pf.secType == 'STK') &\n",
    "                              ~pf.symbol.isin(pf[(pf.strategy == 'covering')].symbol) &\n",
    "                              pf.symbol.isin(pf[(pf.strategy == 'protecting')].symbol)]\n",
    "    pf.loc[stocks_protected_only.index, 'strategy'] = 'uncovered'\n",
    "    \n",
    "    # Update strategy field for orphaned options\n",
    "    pf.loc[(pf.strategy == 'tbd') & (pf.secType == 'OPT'), 'strategy'] = 'orphaned'\n",
    "    \n",
    "    # Update strategy field for exposed stock positions\n",
    "    pf.loc[(pf.strategy == 'tbd') & (pf.secType == 'STK'), 'strategy'] = 'exposed'\n",
    "    \n",
    "    return pf\n",
    "\n",
    "pf = make_strategy(pf)\n",
    "\n",
    "pickle_me(pf, pf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pf.drop(columns='contract').round(2)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in price, und_hv, and und_iv columns\n",
    "null_rows = pf[pf[['und_price', 'und_hv', 'und_iv']].isnull().any(axis=1)]\n",
    "print(\"Portfolio with null values in price, historical vol or implied vol:\")\n",
    "display(null_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cook orders \n",
    "<b>For existing positions</b>\n",
    "- `Exposed` and `Uncovered` stocks should be covered\n",
    "   - ...both for long (covered call) and short (covered put)\n",
    "- `Exposed` and `Unprotected` stocks should be protected\n",
    "   - ...both for long (protective put) and short (protective call)\n",
    "- `Orphaned` stocks should be liquidated\n",
    "\n",
    "<b>For rest of the symbols</b>\n",
    "- Symbols with announcements in a week need to be straddled\n",
    "- Remaining ones should have naked puts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cook Covered Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ib_async import Option\n",
    "\n",
    "from ibfuncs import qualify_me\n",
    "from utils import (black_scholes, clean_ib_util_df, get_dte, get_prec, us_repo_rate)\n",
    "\n",
    "COVER_MIN_DTE = config.get('COVER_MIN_DTE')\n",
    "\n",
    "\n",
    "# Get exposed and uncovered long\n",
    "uncov = pf.strategy.isin(['exposed', 'uncovered'])\n",
    "uncov_long = pf[uncov & (pf.position > 0)].reset_index(drop=True)\n",
    "\n",
    "# Ready the chains for portfolio symbols\n",
    "df_cc = (chains[chains.symbol.isin(uncov_long.symbol.unique())]\n",
    "            .loc[(chains.dte.between(COVER_MIN_DTE, COVER_MIN_DTE+7))]\n",
    "            [['symbol', 'expiry', 'strike', 'dte']]\n",
    "            .sort_values(['symbol', 'dte'])\n",
    "            .reset_index(drop=True))\n",
    "\n",
    "df = chains[chains.symbol.isin(uncov_long.symbol.unique())]\n",
    "\n",
    "# Merge chains with underlying prices and volatilities\n",
    "df_cc = df_cc.merge(unds_iv, on='symbol', how='left')\n",
    "\n",
    "# Calculate standard deviation based on implied volatility and days to expiration\n",
    "df_cc['sdev'] = df_cc.und_price * df_cc.und_iv * (df_cc.dte / 365)**0.5\n",
    "\n",
    "# For each symbol and expiry, get 3 strikes above und_price + sdev\n",
    "\n",
    "cc_std = config.get('COVER_STD_MULT')\n",
    "no_of_options = 3\n",
    "\n",
    "cc_long = (\n",
    "    df_cc.groupby(['symbol', 'expiry'])\n",
    "    .apply(lambda x: x[x['strike'] > x['und_price'] + cc_std * x['sdev']]\n",
    "                    .assign(diff=abs(x['strike'] - (x['und_price'] + cc_std * x['sdev'])))\n",
    "                    .sort_values('diff')\n",
    "                    .head(no_of_options), include_groups=False)\n",
    "    .reset_index()\n",
    "    .drop(columns=['level_2', 'diff'])\n",
    ")\n",
    "\n",
    "# Make long covered call options\n",
    "cov_calls = [\n",
    "    Option(s, e, k, 'C', \"SMART\")\n",
    "    for s, e, k in zip(cc_long.symbol, cc_long.expiry, cc_long.strike)\n",
    "    ]\n",
    "\n",
    "with get_ib('SNP') as ib:\n",
    "    asyncio.run(qualify_me(ib, cov_calls))\n",
    "\n",
    "df_cc1 = clean_ib_util_df([c for c in cov_calls if c.conId > 0])\n",
    "\n",
    "# Get the lower of the long covered call\n",
    "df_ccf = df_cc1.loc[df_cc1.groupby('symbol')['strike'].idxmin()]\n",
    "\n",
    "# Get the price and IV of the covered calls\n",
    "with get_ib('SNP') as ib:\n",
    "    df_ccf = ib.run(df_iv(ib=ib, \n",
    "                          stocks=df_ccf.contract.to_list(), \n",
    "                          msg='cc option ivs', sleep_time=15)).drop(columns='hv')\n",
    "# Merge the DataFrames on the 'symbol' column\n",
    "merged_df = df_ccf.merge(df_cc.groupby('symbol').head(1)[['symbol', 'und_price', 'und_iv']], on='symbol', how='left')\n",
    "\n",
    "# Reorder the columns to place 'und_price' and 'und_iv' as the 6th and 7th columns\n",
    "columns = list(df_ccf.columns)[:5] + ['und_price', 'und_iv'] + list(df_ccf.columns)[5:]\n",
    "merged_df = merged_df[columns]\n",
    "\n",
    "# Calculate qty by dividing the position by 100\n",
    "uncov_long['qty'] = uncov_long['position'] / 100\n",
    "\n",
    "# Merge df_ccf with uncov_long on the 'symbol' column\n",
    "merged_df = merged_df.merge(uncov_long[['symbol', 'qty']], on='symbol', how='left')\n",
    "\n",
    "# Add the 'action' column with the value 'Sell'\n",
    "merged_df['action'] = 'Sell'\n",
    "\n",
    "merged_df.insert(4, 'dte', merged_df.expiry.apply(get_dte))\n",
    "\n",
    "# Get the black scholes price\n",
    "\n",
    "# Parameters for the Black-Scholes model\n",
    "r = us_repo_rate()\n",
    "\n",
    "# Calculate option prices using the black_scholes function\n",
    "bs_price = merged_df.apply(lambda row: black_scholes(\n",
    "    S=row['und_price'],\n",
    "    K=row['strike'],\n",
    "    T=row['dte']/365,\n",
    "    r=r,\n",
    "    sigma=row['und_iv'],  # Use 'und_iv' for implied volatility\n",
    "    option_type=row['right']\n",
    "), axis=1)\n",
    "merged_df.insert(12, 'bs_price', bs_price)\n",
    "\n",
    "# Calculate the 4th quartile (75th percentile) of bs_price and price\n",
    "merged_df['xPrice'] = merged_df.apply(lambda row: row[['bs_price', 'price']].quantile(0.25) if row['price'] < row['bs_price'] else row['price'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready to place covered call orders!\n",
    "df_ccx = merged_df\n",
    "\n",
    "# Merge avgCost and unPnL from pf based on symbol\n",
    "merged_pnl = pf[['symbol', 'avgCost', 'unPnL']].merge(df_ccx[['symbol']], on='symbol', how='right')\n",
    "\n",
    "# Divide df_ccx.unPnL by (df_ccx.qty * 100) and rename unPnL to pnl\n",
    "df_ccx = df_ccx.merge(merged_pnl, on='symbol', how='left')\n",
    "df_ccx['pnl'] = df_ccx['unPnL'] / (df_ccx['qty'] * 100)\n",
    "\n",
    "df_ccx.xPrice = df_ccx['price'].apply(lambda x: max(x, config.get('MINEXPOPTPRICE')))\n",
    "\n",
    "df_ccx['maxPnL'] = df_ccx['strike'] - df_ccx['avgCost'] + df_ccx['unPnL'] + df_ccx['xPrice']*100\n",
    "columns = list(df_ccx.columns)\n",
    "new_order = columns[:columns.index('und_price') + 1] + columns[columns.index('und_price') + 2:]\n",
    "df_ccx = df_ccx[new_order].sort_values('maxPnL', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_ccx.drop(columns=['contract', 'expiry', 'iv']).round(2)\n",
    "df_temp.maxPnL.sum()-pf.unPnL.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle short stock positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ib_async import Option\n",
    "\n",
    "from ibfuncs import qualify_me  # Assuming qualify_me handles put options as well\n",
    "from utils import clean_ib_util_df, get_dte, us_repo_rate\n",
    "\n",
    "\n",
    "# Get exposed and uncovered short\n",
    "uncov_short = pf[uncov & (pf.position < 0)].reset_index(drop=True)\n",
    "\n",
    "# Ready the chains for portfolio symbols\n",
    "df_cp = (chains[chains.symbol.isin(uncov_short.symbol.unique())]\n",
    "         .loc[(chains.dte.between(COVER_MIN_DTE, COVER_MIN_DTE+7))]\n",
    "         [['symbol', 'expiry', 'strike', 'dte']]\n",
    "         .sort_values(['symbol', 'dte'])\n",
    "         .reset_index(drop=True))\n",
    "\n",
    "# Merge chains with underlying prices and volatilities\n",
    "df_cp = df_cp.merge(unds_iv, on='symbol', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! TEMPORARY\n",
    "uncov_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate standard deviation based on implied volatility and days to expiration\n",
    "df_cp['sdev'] = df_cp.und_price * df_cp.und_iv * (df_cp.dte / 365)**0.5\n",
    "\n",
    "# For each symbol and expiry, get 3 strikes below und_price - sdev\n",
    "cp_short = (\n",
    "    df_cp.groupby(['symbol', 'expiry'])\n",
    "    .apply(lambda x: x[x['strike'] < x['und_price'] - cc_std * x['sdev']]\n",
    "               .assign(diff=abs(x['strike'] - (x['und_price'] - cc_std * x['sdev'])))\n",
    "               .sort_values('diff')\n",
    "               .head(no_of_options), include_groups=False)\n",
    "    .reset_index()\n",
    "    .drop(columns=['level_2', 'diff'])\n",
    ")\n",
    "# Make covered put options\n",
    "\n",
    "cov_puts = [\n",
    "    Option(s, e, k, 'P', \"SMART\")  # Use 'P' for Put options\n",
    "    for s, e, k in zip(cp_short.symbol, cp_short.expiry, cp_short.strike)\n",
    "]\n",
    "\n",
    "with get_ib('SNP') as ib:\n",
    "    asyncio.run(qualify_me(ib, cov_puts))\n",
    "\n",
    "df_cp1 = clean_ib_util_df([c for c in cov_puts if c.conId > 0])\n",
    "\n",
    "# Get the higher (more profitable) covered put\n",
    "df_cpf = df_cp1.loc[df_cp1.groupby('symbol')['strike'].idxmax()]\n",
    "\n",
    "# Get the price and IV of the short covered puts\n",
    "with get_ib('SNP') as ib:\n",
    "    df_cpf = ib.run(df_iv(ib=ib, \n",
    "                          stocks=df_cpf.contract.to_list(), \n",
    "                          msg='cput ivs', sleep_time=15)).drop(columns='hv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on the 'symbol' column\n",
    "merged_df = df_cpf.merge(df_cp.groupby('symbol').head(1)[['symbol', 'und_price', 'und_iv']], on='symbol', how='left')\n",
    "\n",
    "# Reorder the columns to place 'und_price' and 'und_iv' as the 6th and 7th columns\n",
    "columns = list(df_cpf.columns)[:5] + ['und_price', 'und_iv'] + list(df_cpf.columns)[5:]\n",
    "merged_df = merged_df[columns]\n",
    "\n",
    "# Calculate qty by dividing the position by 100 (assuming uncov_short has a 'position' column)\n",
    "uncov_short['qty'] = uncov_short['position'] / 100\n",
    "\n",
    "# Merge df_cpf with uncov_short on the 'symbol' column\n",
    "merged_df = merged_df.merge(uncov_short[['symbol', 'qty']], on='symbol', how='left')\n",
    "\n",
    "# Add the 'action' column with the value 'Sell'\n",
    "merged_df['action'] = 'Sell'\n",
    "\n",
    "merged_df.insert(4, 'dte', merged_df.expiry.apply(get_dte))\n",
    "\n",
    "# Get the black scholes price\n",
    "\n",
    "# Parameters for the Black-Scholes model\n",
    "r = 0.01 # risk-free rate (1%)\n",
    "\n",
    "r = us_repo_rate()  # Update with actual risk-free rate function\n",
    "\n",
    "# Calculate option prices using the black_scholes function\n",
    "bs_price = merged_df.apply(lambda row: black_scholes(\n",
    "    S=row['und_price'],\n",
    "    K=row['strike'],\n",
    "    T=row['dte']/365,\n",
    "    r=r,\n",
    "    sigma=row['und_iv'], # Use 'und_iv' for implied volatility\n",
    "    option_type=row['right']\n",
    "), axis=1)\n",
    "\n",
    "# Round bs_price to 2 decimal places\n",
    "bs_price = bs_price.round(2)\n",
    "\n",
    "merged_df.insert(12, 'bs_price', bs_price)\n",
    "\n",
    "# Calculate the 4th quartile (75th percentile) of bs_price and price\n",
    "merged_df['xPrice'] = merged_df.apply(lambda row: row[['bs_price', 'price']].quantile(0.75) if row['price'] < row['bs_price'] else row['price'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure xPrice is at least MINEXPOPTPRICE\n",
    "\n",
    "MINEXPOPTPRICE = config.get('MINEXPOPTPRICE')\n",
    "merged_df['xPrice'] = merged_df.apply(\n",
    "    lambda row: max(max(row['bs_price'], row['price']), MINEXPOPTPRICE) if row['price'] < row['bs_price'] else max(row['price'], MINEXPOPTPRICE), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Ready to place covered put orders\n",
    "df_cpx = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Management\n",
    "## Check for covered open orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish open order removes\n",
    "\n",
    "with get_ib('SNP') as ib:\n",
    "    pf_raw = quick_pf(ib)\n",
    "    oo = get_open_orders(ib)\n",
    "    \n",
    "if isinstance(oo, pd.DataFrame) and not oo.empty:\n",
    "    long_cover_remove = oo[(oo.right == 'C') & (oo.symbol.isin(uncov_long.symbol.to_list()))].symbol.to_list()\n",
    "    # remove long covers that are there in the portfolio due to recent order fulfilment\n",
    "    py = pd.merge(\n",
    "        pf_raw,\n",
    "        df_ccx[['secType', 'symbol', 'right']],\n",
    "        on=['secType', 'symbol', 'right'],\n",
    "        how='inner'\n",
    "    ).symbol.to_list()\n",
    "\n",
    "    long_cover_remove.extend(py)\n",
    "\n",
    "    short_cover_remove = oo[(oo.right == 'P') & (oo.symbol.isin(uncov_short.symbol.to_list()))].symbol.to_list()\n",
    "\n",
    "    # remove short covers that are there in the portfolio due to recent order fulfilment\n",
    "    px = pd.merge(\n",
    "        pf_raw,\n",
    "        df_cpx[['secType', 'symbol', 'right']],\n",
    "        on=['secType', 'symbol', 'right'],\n",
    "        how='inner'\n",
    "    ).symbol.to_list()\n",
    "\n",
    "    short_cover_remove.extend(px)\n",
    "else:\n",
    "    long_cover_remove = short_cover_remove = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_longs = df_ccx[~df_ccx.symbol.isin(long_cover_remove)]\n",
    "cover_shorts = df_cpx[~df_cpx.symbol.isin(short_cover_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Covered Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "from ib_async import IB, LimitOrder\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# create contract orders\n",
    "def make_ib_orders(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"Make (contract, order) tuples\"\"\"\n",
    "\n",
    "    contracts = df.contract.to_list()\n",
    "    orders = [\n",
    "        LimitOrder(action=action, totalQuantity=abs(int(q)), lmtPrice=get_prec(p, 0.01))\n",
    "        for action, q, p in zip(df.action, df.qty, df.xPrice)\n",
    "    ]\n",
    "\n",
    "    cos = tuple((c, o) for c, o in zip(contracts, orders))\n",
    "\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_orders(ib: IB, cos: Union[tuple, list], blk_size: int = 25) -> List:\n",
    "    \"\"\"!!!CAUTION!!!: This places orders in the system\n",
    "    ---\n",
    "    NOTE: cos could be a single (contract, order)\n",
    "          or a tuple/list of ((c1, o1), (c2, o2)...)\n",
    "          made using tuple(zip(cts, ords))\n",
    "    ---\n",
    "    USAGE:\n",
    "    ---\n",
    "    cos = tuple((c, o) for c, o in zip(contracts, orders))\n",
    "    with IB().connect(port=port) as ib:\n",
    "        ordered = place_orders(ib=ib, cos=cos)\n",
    "    \"\"\"\n",
    "\n",
    "    trades = []\n",
    "\n",
    "    if isinstance(cos, (tuple, list)) and (len(cos) == 2):\n",
    "        c, o = cos\n",
    "        trades.append(ib.placeOrder(c, o))\n",
    "\n",
    "    else:\n",
    "        cobs = {cos[i : i + blk_size] for i in range(0, len(cos), blk_size)}\n",
    "\n",
    "        for b in tqdm(cobs):\n",
    "            for c, o in b:\n",
    "                td = ib.placeOrder(c, o)\n",
    "                trades.append(td)\n",
    "            ib.sleep(0.75)\n",
    "\n",
    "    return trades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!! PLACE COVERED ORDERS !!!\n",
    "## *** Be Careful ***"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "with get_ib('SNP') as ib:\n",
    "    longs = place_orders(ib, make_ib_orders(cover_longs))\n",
    "    shorts = place_orders(ib, make_ib_orders(cover_shorts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Unprotected Longs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROT_MIN_DTE = config.get('PROT_MIN_DTE')\n",
    "\n",
    "# Get exposed and protected long\n",
    "unprot = pf.strategy.isin(['exposed', 'unprotected'])\n",
    "unprot_long = pf[unprot & (pf.position > 0)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 'chains' and 'unprot_long' dataframes on the 'symbol' field\n",
    "df = pd.merge(chains, unprot_long.drop(columns = ['strike', 'right', 'expiry']), on='symbol', how='left').dropna()\n",
    "\n",
    "# Filter the dataframe to keep only the rows with dte closest to 45 days\n",
    "df = df.loc[(df['dte'] - 45).abs() == (df['dte'] - 45).abs().min()]\n",
    "\n",
    "# Sort the dataframe by symbol and strike\n",
    "df = df.sort_values(['symbol', 'strike'], ascending=[True, True])\n",
    "\n",
    "# Group the dataframe by symbol\n",
    "grouped = df.groupby('symbol')\n",
    "\n",
    "# Remove the last 2 rows of each symbol\n",
    "df_trimmed = grouped.apply(lambda x: x.iloc[:-2], include_groups=False)\n",
    "\n",
    "# Keep the last 2 rows of each symbol and remove the rest\n",
    "df_final = grouped.apply(lambda x: x.iloc[-2:], include_groups=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final\n",
    "df_final.reset_index(level=1, drop=True).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to get the rows with dte closest to 45 days\n",
    "df = df[df['dte'].abs() - 45 == df['dte'].abs() - 45].sort_values('dte').drop_duplicates('symbol', keep='first')\n",
    "\n",
    "# Group the dataframe by 'symbol' and get two rows with strikes below unprot_long.und_price\n",
    "df = df.sort_values('strike').groupby('symbol').apply(lambda x: x.iloc[:2] if x['strike'].min() < x['und_price'].iloc[0] else x.iloc[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
